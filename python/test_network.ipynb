{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantized SNN for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNN\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "from snntorch.functional import quant\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "# Quantization\n",
    "import brevitas.nn as qnn\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Other\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_epochs\": 1,       # Number of epochs to train for (per trial)\n",
    "    \"batch_size\": 128,      # Batch size\n",
    "    \"seed\": 0,              # Random seed\n",
    "    \n",
    "    # Quantization\n",
    "    \"num_bits\": 4,          # Bit resolution\n",
    "    \n",
    "    # Network parameters\n",
    "    \"grad_clip\": False,     # Whether or not to clip gradients\n",
    "    \"weight_clip\": False,   # Whether or not to clip weights\n",
    "    \"batch_norm\": True,     # Whether or not to use batch normalization\n",
    "    \"dropout\": 0.07,        # Dropout rate\n",
    "    \"beta\": 1.00,           # Decay rate parameter (beta)\n",
    "    \"threshold\": 30,        # Threshold parameter (theta)\n",
    "    \"lr\": 3.0e-3,           # Initial learning rate\n",
    "    \"slope\": 5.6,           # Slope value (k)\n",
    "    \n",
    "    # Fixed params\n",
    "    \"num_steps\": 100,       # Number of timesteps to encode input for\n",
    "    \"correct_rate\": 0.8,    # Correct rate\n",
    "    \"incorrect_rate\": 0.2,  # Incorrect rate\n",
    "    \"betas\": (0.9, 0.999),  # Adam optimizer beta values\n",
    "    \"t_0\": 4690,            # Initial frequency of the cosine annealing scheduler\n",
    "    \"eta_min\": 0,           # Minimum learning rate\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.num_bits   = config[\"num_bits\"]\n",
    "        self.thr        = config[\"threshold\"]\n",
    "        self.slope      = config[\"slope\"]\n",
    "        self.beta       = config[\"beta\"]\n",
    "        self.num_steps  = config[\"num_steps\"]\n",
    "        \n",
    "        # Initialize Layers\n",
    "        self.fc1        = qnn.QuantLinear(9, 3, bias=False, weight_bit_width=self.num_bits)\n",
    "        self.lif1       = snn.Leaky(self.beta, threshold=self.thr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden states and outputs at t=0\n",
    "        mem = self.lif1.init_leaky()\n",
    "        \n",
    "        # Record the final layer\n",
    "        spk_rec = []\n",
    "        mem_rec = []\n",
    "        for step in range(self.num_steps):\n",
    "            cur = self.fc1(x[step])\n",
    "            spk, mem = self.lif1(cur, mem)\n",
    "\n",
    "            spk_rec.append(spk)\n",
    "            mem_rec.append(mem)\n",
    "        \n",
    "        return torch.stack(spk_rec), torch.stack(mem_rec)\n",
    "\n",
    "net = Net(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    manual_weights = torch.ones((3, 9), device=net.fc1.weight.device)\n",
    "    net.fc1.weight.copy_(manual_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrn_idx_list = [0, 1, 2]\n",
    "weights_list = [0.25, -0.5, 0.5]\n",
    "with torch.no_grad():\n",
    "    for nrn_idx, weight in zip(nrn_idx_list, weights_list):\n",
    "        net.fc1.weight[nrn_idx, :] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.lif1.threshold/net.fc1.quant_weight().scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This seems to work\n",
    "net.fc1.quant_weight()/net.fc1.quant_weight().scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps   = 100\n",
    "batch_size  = 1\n",
    "channels    = 1\n",
    "length      = 9\n",
    "\n",
    "data = torch.zeros((timesteps, batch_size, length))\n",
    "data[:, :, 0] = 1.0\n",
    "\n",
    "spk_rec, mem_rec = net(data)\n",
    "spk_rec = spk_rec.detach().numpy()\n",
    "mem_rec = mem_rec.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 100, 1)\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(16, 6))\n",
    "ax[0, 0].plot(x, mem_rec[:, 0, 0], label=\"nrn = 0\")\n",
    "ax[1, 0].plot(x, mem_rec[:, 0, 1], label=\"nrn = 1\")\n",
    "ax[2, 0].plot(x, mem_rec[:, 0, 2], label=\"nrn = 2\")\n",
    "ax[0, 1].plot(x, spk_rec[:, 0, 0], label=\"nrn = 0\")\n",
    "ax[1, 1].plot(x, spk_rec[:, 0, 1], label=\"nrn = 1\")\n",
    "ax[2, 1].plot(x, spk_rec[:, 0, 2], label=\"nrn = 2\")\n",
    "\n",
    "ax[0, 0].set_title(\"mem_rec\")\n",
    "ax[0, 1].set_title(\"spk_rec\")\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.legend(loc=\"upper left\")\n",
    "\n",
    "fig.suptitle(\"snntorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "### `tb2`\n",
    "\n",
    "```py\n",
    "nrn_idx_list = [0, 1, 2]\n",
    "weights_list = [0.25, -0.5, 0.5]\n",
    "with torch.no_grad():\n",
    "    for nrn_idx, weight in zip(nrn_idx_list, weights_list):\n",
    "        net.fc1.weight[nrn_idx, :] = weight\n",
    "```\n",
    "\n",
    "### `tb1`\n",
    "\n",
    "- 9 to 3 fc\n",
    "- first weight is 0, other are 1 (7)\n",
    "\n",
    "first line in `syn_init.data`\n",
    "```\n",
    "01110111011101110111011101110000\n",
    "```\n",
    "\n",
    "- threshold is 30 (210)\n",
    "\n",
    "### `tb0`\n",
    "\n",
    "- 9 to 3 fc\n",
    "- all weights are 1 (7)\n",
    "- threshold is 30 (210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_to_signed_int(bstr, bits=12):\n",
    "    \"\"\"Convert binary string to signed integer.\"\"\"\n",
    "    val = int(bstr, 2)\n",
    "    if val >= 2**(bits - 1):\n",
    "        val -= 2**bits\n",
    "    return val\n",
    "\n",
    "df = pd.read_csv('data/testbench/tb2_mem_rec.csv', names=['nrnwrt_mem_addr', 'nrnwrt_mem_data'])\n",
    "tb_mem_rec = df['nrnwrt_mem_data'].to_numpy()\n",
    "tb_mem_rec_2 = [s[0:12] for s in tb_mem_rec]\n",
    "tb_mem_rec_1 = [s[12:24] for s in tb_mem_rec]\n",
    "tb_mem_rec_0 = [s[24:36] for s in tb_mem_rec]\n",
    "tb_mem_rec_0_int = [bin_to_signed_int(b, bits=12) for b in tb_mem_rec_0]\n",
    "tb_mem_rec_1_int = [bin_to_signed_int(b, bits=12) for b in tb_mem_rec_1]\n",
    "tb_mem_rec_2_int = [bin_to_signed_int(b, bits=12) for b in tb_mem_rec_2]\n",
    "\n",
    "x = np.arange(0, 100, 1)\n",
    "\n",
    "df = pd.read_csv('data/testbench/tb2_spk_rec.csv', names=['event_number', 'out_fifo_wdata'])\n",
    "df['out_fifo_wdata'] = df['out_fifo_wdata'].apply(lambda b: int(str(b), 2))\n",
    "\n",
    "x = np.arange(0, 100, 1)\n",
    "nrn_0 = np.zeros_like(x)\n",
    "nrn_1 = np.zeros_like(x)\n",
    "nrn_2 = np.zeros_like(x)\n",
    "\n",
    "for event, nrn in zip(df['event_number'], df['out_fifo_wdata']):\n",
    "    if nrn == 0:\n",
    "        nrn_0[event] = 1\n",
    "    elif nrn == 1:\n",
    "        nrn_1[event] = 1\n",
    "    elif nrn == 2:\n",
    "        nrn_2[event] = 1\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(16, 6))\n",
    "ax[0, 0].plot(x, tb_mem_rec_0_int, label=\"nrn = 0\")\n",
    "ax[1, 0].plot(x, tb_mem_rec_1_int, label=\"nrn = 1\")\n",
    "ax[2, 0].plot(x, tb_mem_rec_2_int, label=\"nrn = 2\")\n",
    "ax[0, 1].plot(x, nrn_0, label=\"nrn = 0\")\n",
    "ax[1, 1].plot(x, nrn_1, label=\"nrn = 1\")\n",
    "ax[2, 1].plot(x, nrn_2, label=\"nrn = 2\")\n",
    "\n",
    "ax[0, 0].set_title(\"mem_rec\")\n",
    "ax[0, 1].set_title(\"spk_rec\")\n",
    "\n",
    "for a in ax.flatten():\n",
    "    a.legend(loc=\"upper left\")\n",
    "\n",
    "fig.suptitle(\"testbench\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
