{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5038068",
   "metadata": {},
   "source": [
    "# Quantized SNN for N-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf438cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNN\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "from snntorch.functional import quant\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "# Quantization\n",
    "import brevitas.nn as qnn\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Tonic\n",
    "import tonic\n",
    "from tonic import DiskCachedDataset\n",
    "from tonic import MemoryCachedDataset\n",
    "\n",
    "# Other\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pyfenrir as fenrir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dafe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_size = tonic.datasets.NMNIST.sensor_size\n",
    "batch_size = 128\n",
    "n_timesteps = 100\n",
    "\n",
    "def pad_time_dimension(frames, fixed_time_steps=100):\n",
    "    \"\"\"\n",
    "    Pad or truncate the time dimension of frames to a fixed number of time steps.\n",
    "    Input: frames [time, channels, height, width] (numpy or tensor)\n",
    "    Output: frames [fixed_time_steps, channels, height, width] (tensor)\n",
    "    \"\"\"\n",
    "    # Convert to tensor if input is numpy array\n",
    "    if isinstance(frames, np.ndarray):\n",
    "        frames = torch.tensor(frames, dtype=torch.float)\n",
    "    current_time_steps = frames.shape[0]\n",
    "    #print(f\"Current time steps: {current_time_steps}, Fixed time steps: {fixed_time_steps}\")\n",
    "    if current_time_steps > fixed_time_steps:\n",
    "        return frames[:fixed_time_steps]\n",
    "    elif current_time_steps < fixed_time_steps:\n",
    "        return torch.nn.functional.pad(frames, (0, 0, 0, 0, 0, 0, 0, fixed_time_steps - current_time_steps))\n",
    "    return frames\n",
    "\n",
    "frame_transform = transforms.Compose([\n",
    "    tonic.transforms.Downsample(spatial_factor=16/34),                                  # Downscale 34×34 to 16×16\n",
    "    tonic.transforms.ToFrame(sensor_size=(16, 16, 2), time_window=1000),                # Convert to frames, 10ms bins\n",
    "    transforms.Lambda(lambda x: pad_time_dimension(x, fixed_time_steps=n_timesteps)),   # Pad/truncate time dimension\n",
    "    transforms.Lambda(lambda x: torch.clamp(torch.tensor(x), 0, 1).type(torch.float)),  # Clamp spikes accumulted over time to (0,1)\n",
    "    transforms.Lambda(lambda x: x[:, 1, :, :]  ),                                       # Select only ON channel\n",
    "    transforms.Lambda(lambda x: x.flatten(start_dim=1)),  \n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "trainset = tonic.datasets.NMNIST(save_to='./data', transform=frame_transform, train=True)\n",
    "testset = tonic.datasets.NMNIST(save_to='./data', transform=frame_transform, train=False)\n",
    "\n",
    "cached_trainset = MemoryCachedDataset(trainset)\n",
    "cached_testset = MemoryCachedDataset(testset)\n",
    "\n",
    "# Define your dataloaders...\n",
    "trainloader = DataLoader(cached_trainset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "testloader = DataLoader(cached_testset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_epochs\": 1,       # Number of epochs to train for (per trial)\n",
    "    \"batch_size\": batch_size,      # Batch size\n",
    "    \"seed\": 0,              # Random seed\n",
    "    \n",
    "    # Quantization\n",
    "    \"num_bits\": 4,          # Bit resolution\n",
    "    \n",
    "    # Network parameters\n",
    "    \"grad_clip\": False,     # Whether or not to clip gradients\n",
    "    \"weight_clip\": False,   # Whether or not to clip weights\n",
    "    \"batch_norm\": True,     # Whether or not to use batch normalization\n",
    "    \"dropout\": 0.07,        # Dropout rate\n",
    "    \"beta\": 1.0,           # Decay rate parameter (beta)\n",
    "    \"threshold\": 10,        # Threshold parameter (theta)\n",
    "    \"lr\": 3.0e-3,           # Initial learning rate\n",
    "    \"slope\": 5.6,           # Slope value (k)\n",
    "    \n",
    "    # Fixed params\n",
    "    \"num_steps\": 100,       # Number of timesteps to encode input for\n",
    "    \"correct_rate\": 0.8,    # Correct rate\n",
    "    \"incorrect_rate\": 0.2,  # Incorrect rate\n",
    "    \"betas\": (0.9, 0.999),  # Adam optimizer beta values\n",
    "    \"t_0\": 4690,            # Initial frequency of the cosine annealing scheduler\n",
    "    \"eta_min\": 0,           # Minimum learning rate\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de18f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.num_bits   = config[\"num_bits\"]\n",
    "        self.thr        = config[\"threshold\"]\n",
    "        self.slope      = config[\"slope\"]\n",
    "        self.num_steps  = config[\"num_steps\"]\n",
    "        self.batch_norm = config[\"batch_norm\"]\n",
    "        \n",
    "        self.beta1 = torch.nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
    "        self.beta2 = torch.nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
    "        self.beta3 = torch.nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
    "\n",
    "        # Input layer (16x16 = 256)\n",
    "        self.fc1        = qnn.QuantLinear(16*16, 256, bias=False, weight_bit_width=4)\n",
    "        self.lif1       = snn.Leaky(beta=1.0, threshold=1.0, learn_threshold=True, reset_mechanism='zero', reset_delay=False)\n",
    "\n",
    "        # Hidden layer (256) to output layer (10)\n",
    "        self.fc2        = qnn.QuantLinear(256, 128, bias=False, weight_bit_width=4)\n",
    "        self.lif2       = snn.Leaky(beta=1.0, threshold=1.0, learn_threshold=True, reset_mechanism='zero', reset_delay=False)\n",
    "\n",
    "        # Hidden layer (128) to output layer (10)\n",
    "        self.fc3        = qnn.QuantLinear(128, 10, bias=False, weight_bit_width=4)\n",
    "        self.lif3       = snn.Leaky(beta=1.0, threshold=1.0, learn_threshold=True, reset_mechanism='zero', reset_delay=False)\n",
    "\n",
    "    def _beta_clamp(self, mem, beta):\n",
    "        mem = torch.where(\n",
    "            mem > 0,\n",
    "            torch.clamp(mem - torch.abs(beta), min=0.0),\n",
    "            mem\n",
    "        )\n",
    "        mem = torch.where(\n",
    "            mem < 0,\n",
    "            torch.clamp(mem + torch.abs(beta), max=0.0),\n",
    "            mem\n",
    "        )\n",
    "        return mem\n",
    "\n",
    "    def _mem_clamp(self, mem, scale, multiplier, bits=12):\n",
    "        max_val = (2**(bits - 1)) - 1\n",
    "        max_val = max_val * scale / multiplier\n",
    "        min_val = -(2**(bits - 1)) - 1\n",
    "        min_val = min_val * scale / multiplier\n",
    "\n",
    "        mem = torch.clamp(mem, min=min_val, max=max_val)\n",
    "\n",
    "        return mem\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden states and outputs at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "        \n",
    "        # Record all layers for debugging\n",
    "        spk_rec1 = []\n",
    "        mem_rec1 = []\n",
    "        spk_rec2 = []\n",
    "        mem_rec2 = []\n",
    "        spk_rec3 = []\n",
    "        mem_rec3 = []\n",
    "\n",
    "        scale_fc1 = self.fc1.quant_weight().scale\n",
    "        scale_fc2 = self.fc2.quant_weight().scale\n",
    "        scale_fc3 = self.fc3.quant_weight().scale\n",
    "\n",
    "        for step in range(self.num_steps):\n",
    "            cur1 = self.fc1(x[:, step, :])\n",
    "            mem1 = self._mem_clamp(mem1, scale_fc1, multiplier=10)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            mem1 = self._beta_clamp(mem1, self.beta1)\n",
    "\n",
    "            cur2 = self.fc2(spk1)\n",
    "            mem2 = self._mem_clamp(mem2, scale_fc2, multiplier=10)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            mem2 = self._beta_clamp(mem2, self.beta2)\n",
    "\n",
    "            cur3 = self.fc3(spk2)\n",
    "            mem3 = self._mem_clamp(mem3, scale_fc3, multiplier=10)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "            mem3 = self._beta_clamp(mem3, self.beta3)\n",
    "\n",
    "            spk_rec1.append(spk1)\n",
    "            mem_rec1.append(mem1)\n",
    "            spk_rec2.append(spk2)\n",
    "            mem_rec2.append(mem2)\n",
    "            spk_rec3.append(spk3)\n",
    "            mem_rec3.append(mem3)\n",
    "        \n",
    "        return torch.stack(spk_rec1), torch.stack(mem_rec1), torch.stack(spk_rec2), torch.stack(mem_rec2), torch.stack(spk_rec3), torch.stack(mem_rec3)\n",
    "\n",
    "net = Net(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    net.parameters(),\n",
    "    lr=config[\"lr\"],\n",
    "    betas=config[\"betas\"]\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=config[\"t_0\"],\n",
    "    eta_min=config[\"eta_min\"],\n",
    "    last_epoch=-1\n",
    ")\n",
    "\n",
    "criterion = SF.mse_count_loss(\n",
    "    correct_rate=config[\"correct_rate\"],\n",
    "    incorrect_rate=config[\"incorrect_rate\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f96f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, net, trainloader, criterion, optimizer, device=\"cpu\", scheduler=None):\n",
    "    \"\"\"\n",
    "    Complete one epoch of training.\n",
    "    \"\"\"\n",
    "    \n",
    "    net.train()\n",
    "    loss_accum = []\n",
    "    lr_accum = []\n",
    "\n",
    "    for batch_idx, (data, labels) in enumerate(tqdm(trainloader, leave=False, desc=\"Training\")):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        _, _, _, _, spk_rec, _ = net(data)\n",
    "        loss = criterion(spk_rec, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        ## Enable gradient clipping\n",
    "        if config[\"grad_clip\"]:\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "\n",
    "        ## Enable weight clipping\n",
    "        if config[\"weight_clip\"]:\n",
    "            with torch.no_grad():\n",
    "                for param in net.parameters():\n",
    "                    param.clamp_(-1, 1)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        loss_accum.append(loss.item() / config[\"num_steps\"])\n",
    "        lr_accum.append(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    return loss_accum, lr_accum\n",
    "\n",
    "def test(config, net, testloader, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Calculate accuracy on full test set.\n",
    "    \"\"\"\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            _, _, _, _, outputs, _ = net(images)\n",
    "            accuracy = SF.accuracy_rate(outputs, labels)\n",
    "            total += labels.size(0)\n",
    "            correct += accuracy * labels.size(0)\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "loss_list = []\n",
    "lr_list = []\n",
    "\n",
    "## Load model instead of training\n",
    "load_model = True\n",
    "if load_model:\n",
    "    net.load_state_dict(torch.load('models/nmnist_3layer.pth'))\n",
    "else:\n",
    "    print(f\"=======Training Network=======\")\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        loss, lr  = train(config, net, trainloader, criterion, optimizer, device, scheduler)\n",
    "        loss_list = loss_list + loss\n",
    "        lr_list   = lr_list + lr\n",
    "        # Test\n",
    "        test_accuracy = test(config, net, testloader, device)\n",
    "        print(f\"Epoch: {epoch} \\tTest Accuracy: {test_accuracy}\")\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(loss_list, color='tab:orange')\n",
    "    ax2.plot(lr_list, color='tab:blue')\n",
    "    ax1.set_xlabel('Iterations')\n",
    "    ax1.set_ylabel('Loss', color='tab:orange')\n",
    "    ax2.set_ylabel('Learning Rate', color='tab:blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = False\n",
    "if save_model:\n",
    "    dir = \"./models\"\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    torch.save(net.state_dict(), f\"{dir}/nmnist_3layer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b138dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(12, 6))\n",
    "iter_test = iter(testloader)\n",
    "data_it, targets_it = next(iter_test)\n",
    "\n",
    "dataset = testloader.dataset\n",
    "num_samples = len(dataset)\n",
    "ran_idx = torch.randint(0, num_samples, (3,))\n",
    "\n",
    "for i, idx in enumerate(ran_idx):\n",
    "    # Get some data\n",
    "    spike_data, target = dataset[idx]\n",
    "    spike_data = spike_data.unsqueeze(0)\n",
    "    spike_data = spike_data.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    print(spike_data.shape)\n",
    "    _, _, _, _, spk_rec, mem_rec = net(spike_data)\n",
    "\n",
    "    # Besværgelse (just summing the spikes)\n",
    "    pred = torch.argmax(spk_rec.sum(dim=0).squeeze()).item()\n",
    "\n",
    "    # Plot\n",
    "    splt.raster(spk_rec[:, 0].view(100, -1), ax[i], s=25, c=\"black\")\n",
    "    ax[i].set_yticks(np.arange(0, 10, 1))\n",
    "    ax[i].set_title(f\"Prediction: {pred}, Target: {target}\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "spike_sums = spk_rec.sum(dim=0).squeeze()  # shape: [10]\n",
    "spike_avg = spike_sums.sum(dim=0)/10\n",
    "\n",
    "print(f\"Spike counts per neuron: {spike_sums.tolist()}\")\n",
    "print(f\"Average spikes per neuron: {spike_avg.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814cf285",
   "metadata": {},
   "outputs": [],
   "source": [
    "fenrir.export_weights(net.fc1, 32, 256, '../src/design_sources/data/fc1_syn.data')\n",
    "quant_scale = net.fc1.quant_weight().scale\n",
    "beta        = net.beta1/net.fc1.quant_weight().scale\n",
    "thr         = fenrir.get_threshold(net.fc1, net.lif1)\n",
    "print(f\"Quant Scale: {quant_scale}\")\n",
    "print(f\"Beta: {beta}\")\n",
    "print(f\"Threshold: {thr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0d946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fenrir.export_weights(net.fc2, 32, 256, '../src/design_sources/data/fc2_syn.data')\n",
    "quant_scale = net.fc2.quant_weight().scale\n",
    "beta        = net.beta2/net.fc2.quant_weight().scale\n",
    "thr         = fenrir.get_threshold(net.fc2, net.lif2)\n",
    "print(f\"Quant Scale: {quant_scale}\")\n",
    "print(f\"Beta: {beta}\")\n",
    "print(f\"Threshold: {thr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b70c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "fenrir.export_weights(net.fc3, 40, 128, '../src/design_sources/data/fc3_syn.data')\n",
    "quant_scale = net.fc3.quant_weight().scale\n",
    "beta        = net.beta3/net.fc3.quant_weight().scale\n",
    "thr         = fenrir.get_threshold(net.fc3, net.lif3)\n",
    "print(f\"Quant Scale: {quant_scale}\")\n",
    "print(f\"Beta: {beta}\")\n",
    "print(f\"Threshold: {thr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91b3c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select a datapoint from the dataset\n",
    "dataset = testloader.dataset\n",
    "spike_data, target_tmp = dataset[6]\n",
    "\n",
    "## Spike encode it\n",
    "spike_data = spike_data.unsqueeze(0)\n",
    "spike_data = spike_data.to(device)\n",
    "\n",
    "## Forward pass\n",
    "spk_rec1, mem_rec1, spk_rec2, mem_rec2, spk_rec3, mem_rec3 = net(spike_data)\n",
    "pred = torch.argmax(spk_rec3.sum(dim=0).squeeze()).item()\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 6))\n",
    "splt.raster(spike_data[0, :, :].view(100, -1), ax[0], s=25, c=\"black\")\n",
    "splt.raster(spk_rec3[:, 0].view(100, -1), ax[1], s=25, c=\"black\")\n",
    "ax[0].set_title(f\"Prediction: {pred}, Target: {target_tmp}\")\n",
    "\n",
    "## Detach as we will use these for comparison with the testbench\n",
    "spk_rec3 = spk_rec3.cpu().detach().numpy()\n",
    "mem_rec3 = mem_rec3.cpu().detach().numpy()\n",
    "spk_rec2 = spk_rec2.cpu().detach().numpy()\n",
    "mem_rec2 = mem_rec2.cpu().detach().numpy()\n",
    "spk_rec1 = spk_rec1.cpu().detach().numpy()\n",
    "mem_rec1 = mem_rec1.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a77c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = net.fc1.quant_weight()/net.fc1.quant_weight().scale\n",
    "weights = weights.cpu().detach().numpy()\n",
    "\n",
    "in_nrns = [7, 0]\n",
    "weights = weights[16, t_events[9]]\n",
    "\n",
    "weights_sum = weights.sum()\n",
    "\n",
    "print(weights)\n",
    "print(weights_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c2327",
   "metadata": {},
   "outputs": [],
   "source": [
    "## See spikes\n",
    "t = 18\n",
    "\n",
    "spk_rec = spk_rec1\n",
    "\n",
    "spk_events = []\n",
    "nrn_events = []\n",
    "for nrn in range(0, spk_rec.shape[2]):\n",
    "    spk_events.append(spk_rec[t, 0, nrn])\n",
    "\n",
    "for nrn_index, has_spike in enumerate(spk_events):\n",
    "    if has_spike > 0:\n",
    "        nrn_events.append(nrn_index)\n",
    "        print(f\"  Neuron {nrn_index}:\\t {has_spike}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e4dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract input events for specific time index\n",
    "t_events = []\n",
    "\n",
    "tstep_data = spike_data[0, :, :]\n",
    "tstep_data = tstep_data.view(100, -1).cpu().detach().numpy()\n",
    "\n",
    "for tstep in range(0, 100):\n",
    "    temp = tstep_data[tstep, :]\n",
    "    non_zero_indices = np.nonzero(temp)[0]\n",
    "    t_events.append(non_zero_indices.tolist())\n",
    "\n",
    "print(t_events[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ac0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data    = spike_data[0, :, :]\n",
    "tsteps      = exp_data.shape[0]\n",
    "events      = []\n",
    "tstep_event_idx = []\n",
    "\n",
    "for t in range(0, tsteps):\n",
    "    t_data = exp_data[t, :]\n",
    "    non_zero_indices = (t_data != 0).nonzero(as_tuple=True)[0]\n",
    "\n",
    "    for idx in non_zero_indices.tolist():\n",
    "        events.append(idx)\n",
    "\n",
    "    events.append(0b1000000000000)\n",
    "\n",
    "    tstep_event_idx.append(len(events))\n",
    "\n",
    "binary_events = [format(idx, '010b') for idx in events]\n",
    "\n",
    "out_file = 'nmnist_data.txt'\n",
    "with open(out_file, 'w', encoding='utf-8') as f:\n",
    "    for b in binary_events:\n",
    "        if not b == '1000000000000':\n",
    "            f.write(\"000\" + b + '\\n')\n",
    "        else:\n",
    "            f.write(b + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09321a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = (2**(12 - 1)) - 1\n",
    "min_val = -(2**(12 - 1)) - 1\n",
    "max_val = max_val/10\n",
    "min_val = min_val/10\n",
    "\n",
    "for nrn in range(mem_rec2.shape[2]):\n",
    "    mem = mem_rec2[:, 0, nrn]/net.fc2.quant_weight().scale.cpu().detach()\n",
    "    if (mem <= min_val + 40).any():\n",
    "        for t in range(100):\n",
    "            if mem_rec2[t, 0, nrn]/net.fc2.quant_weight().scale.cpu().detach() <= min_val + 40:\n",
    "                print(f\"Min: {nrn}\")\n",
    "                print(f\"t: {t}\")\n",
    "                break\n",
    "    if (mem >= max_val-10).any():\n",
    "        for t in range(100):\n",
    "            if mem_rec2[t, 0, nrn]/net.fc2.quant_weight().scale.cpu().detach() >= max_val:\n",
    "                print(f\"Max: {nrn}\")\n",
    "                print(f\"t: {t}\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f7b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_to_signed_int(bstr, bits=12):\n",
    "    \"\"\"Convert binary string to signed integer.\"\"\"\n",
    "    val = int(bstr, 2)\n",
    "    if val >= 2**(bits - 1):\n",
    "        val -= 2**bits\n",
    "    return val\n",
    "\n",
    "names = ['t', 'nrn_addr', 'val']\n",
    "df_mem = pd.read_csv('../vivado/fenrir/fenrir.sim/sim_1/behav/xsim/mem_rec1.csv', names=names)\n",
    "\n",
    "nrn_mem = {str(i) : [] for i in range(18)}\n",
    "\n",
    "for t in range(1, 101):\n",
    "    subset = df_mem[df_mem['t'] == t][['nrn_addr', 'val']].head(6)\n",
    "    val_list = subset['val'].tolist()\n",
    "\n",
    "    nrn_mem['2'].append(bin_to_signed_int(val_list[0][0:12], bits=12))\n",
    "    nrn_mem['1'].append(bin_to_signed_int(val_list[0][12:24], bits=12))\n",
    "    nrn_mem['0'].append(bin_to_signed_int(val_list[0][24:36], bits=12))\n",
    "    nrn_mem['5'].append(bin_to_signed_int(val_list[1][0:12], bits=12))\n",
    "    nrn_mem['4'].append(bin_to_signed_int(val_list[1][12:24], bits=12))\n",
    "    nrn_mem['3'].append(bin_to_signed_int(val_list[1][24:36], bits=12))\n",
    "    nrn_mem['8'].append(bin_to_signed_int(val_list[2][0:12], bits=12))\n",
    "    nrn_mem['7'].append(bin_to_signed_int(val_list[2][12:24], bits=12))\n",
    "    nrn_mem['6'].append(bin_to_signed_int(val_list[2][24:36], bits=12))\n",
    "    nrn_mem['11'].append(bin_to_signed_int(val_list[3][0:12], bits=12))\n",
    "    nrn_mem['10'].append(bin_to_signed_int(val_list[3][12:24], bits=12))\n",
    "    nrn_mem['9'].append(bin_to_signed_int(val_list[3][24:36], bits=12))\n",
    "    nrn_mem['14'].append(bin_to_signed_int(val_list[4][0:12], bits=12))\n",
    "    nrn_mem['13'].append(bin_to_signed_int(val_list[4][12:24], bits=12))\n",
    "    nrn_mem['12'].append(bin_to_signed_int(val_list[4][24:36], bits=12))\n",
    "    nrn_mem['17'].append(bin_to_signed_int(val_list[5][0:12], bits=12))\n",
    "    nrn_mem['16'].append(bin_to_signed_int(val_list[5][12:24], bits=12))\n",
    "    nrn_mem['15'].append(bin_to_signed_int(val_list[5][24:36], bits=12))\n",
    "\n",
    "names = ['t', 'nrn_addr']\n",
    "df_spk = pd.read_csv('../vivado/fenrir/fenrir.sim/sim_1/behav/xsim/spk_rec1.csv', names=names)\n",
    "df_spk['nrn_addr'] = df_spk['nrn_addr'].apply(lambda b: int(str(b), 2))\n",
    "\n",
    "x = np.arange(100)\n",
    "spks = np.zeros((18, len(x)))\n",
    "for t, nrn_addr in zip(df_spk['t'], df_spk['nrn_addr']):\n",
    "    if nrn_addr < 18 and t < 100:\n",
    "        spks[nrn_addr, t-1] = 1\n",
    "\n",
    "\n",
    "nrn = 1\n",
    "sum_fenrir   = spks[nrn].sum()\n",
    "sum_snntorch = spk_rec1[:, 0, nrn].sum()\n",
    "print(f\"Fenrir spike sum: {sum_fenrir}\")\n",
    "print(f\"snntorch spike sum: {sum_snntorch}\")\n",
    "\n",
    "multiplier = 10\n",
    "scale = net.fc1.quant_weight().scale.cpu().detach().numpy()\n",
    "thr = fenrir.get_threshold(net.fc1, net.lif1)*multiplier\n",
    "\n",
    "x_start = 0\n",
    "x_end   = 100\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 7))\n",
    "ax[0].plot(x, nrn_mem[f\"{nrn}\"], color='red', linewidth=2, alpha=0.5, label=\"TB\")\n",
    "ax[0].plot(mem_rec1[:, 0, nrn]*multiplier/scale, linestyle='--', color='blue', linewidth=2, alpha=0.5, label=\"snntorch\")\n",
    "ax[0].plot(x, np.full_like(x, thr), linestyle='--', color='black', label=\"Thr\")\n",
    "ax[0].plot(x, np.full_like(x, 0), linestyle=':', color='black', alpha=0.5)\n",
    "ax[1].plot(x, spks[nrn], color='red', linewidth=2, alpha=0.5)\n",
    "ax[1].plot(x, spk_rec1[:, 0, nrn], linestyle='--', color='blue', linewidth=2, alpha=0.5)\n",
    "ax[0].set_title(\"mem_rec\")\n",
    "ax[1].set_title(\"spk_rec\")\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xlim(x_start, x_end)\n",
    "    a.set_xticks(np.arange(x_start, x_end + 1, 10))\n",
    "    a.legend(loc=\"upper right\")\n",
    "\n",
    "fig.suptitle(f\"Layer 1, Neuron {nrn}\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_to_signed_int(bstr, bits=12):\n",
    "    \"\"\"Convert binary string to signed integer.\"\"\"\n",
    "    val = int(bstr, 2)\n",
    "    if val >= 2**(bits - 1):\n",
    "        val -= 2**bits\n",
    "    return val\n",
    "\n",
    "names = ['t', 'nrn_addr', 'val']\n",
    "df_mem = pd.read_csv('../vivado/fenrir/fenrir.sim/sim_1/behav/xsim/mem_rec2.csv', names=names)\n",
    "\n",
    "nrn_mem = {str(i) : [] for i in range(18)}\n",
    "\n",
    "for t in range(1, 100):\n",
    "    subset = df_mem[df_mem['t'] == t][['nrn_addr', 'val']].head(6)\n",
    "    val_list = subset['val'].tolist()\n",
    "\n",
    "    nrn_mem['2'].append(bin_to_signed_int(val_list[0][0:12], bits=12))\n",
    "    nrn_mem['1'].append(bin_to_signed_int(val_list[0][12:24], bits=12))\n",
    "    nrn_mem['0'].append(bin_to_signed_int(val_list[0][24:36], bits=12))\n",
    "    nrn_mem['5'].append(bin_to_signed_int(val_list[1][0:12], bits=12))\n",
    "    nrn_mem['4'].append(bin_to_signed_int(val_list[1][12:24], bits=12))\n",
    "    nrn_mem['3'].append(bin_to_signed_int(val_list[1][24:36], bits=12))\n",
    "    nrn_mem['8'].append(bin_to_signed_int(val_list[2][0:12], bits=12))\n",
    "    nrn_mem['7'].append(bin_to_signed_int(val_list[2][12:24], bits=12))\n",
    "    nrn_mem['6'].append(bin_to_signed_int(val_list[2][24:36], bits=12))\n",
    "    nrn_mem['11'].append(bin_to_signed_int(val_list[3][0:12], bits=12))\n",
    "    nrn_mem['10'].append(bin_to_signed_int(val_list[3][12:24], bits=12))\n",
    "    nrn_mem['9'].append(bin_to_signed_int(val_list[3][24:36], bits=12))\n",
    "    nrn_mem['14'].append(bin_to_signed_int(val_list[4][0:12], bits=12))\n",
    "    nrn_mem['13'].append(bin_to_signed_int(val_list[4][12:24], bits=12))\n",
    "    nrn_mem['12'].append(bin_to_signed_int(val_list[4][24:36], bits=12))\n",
    "    nrn_mem['17'].append(bin_to_signed_int(val_list[5][0:12], bits=12))\n",
    "    nrn_mem['16'].append(bin_to_signed_int(val_list[5][12:24], bits=12))\n",
    "    nrn_mem['15'].append(bin_to_signed_int(val_list[5][24:36], bits=12))\n",
    "\n",
    "\n",
    "names = ['t', 'nrn_addr']\n",
    "df_spk = pd.read_csv('../vivado/fenrir/fenrir.sim/sim_1/behav/xsim/spk_rec2.csv', names=names)\n",
    "df_spk['nrn_addr'] = df_spk['nrn_addr'].apply(lambda b: int(str(b), 2))\n",
    "\n",
    "x = np.arange(99)\n",
    "spks = np.zeros((18, len(x)))\n",
    "for t, nrn_addr in zip(df_spk['t'], df_spk['nrn_addr']):\n",
    "    if nrn_addr < 18 and t < 99:\n",
    "        spks[nrn_addr, t-2] = 1\n",
    "\n",
    "nrn = 16\n",
    "sum_fenrir   = spks[nrn].sum()\n",
    "sum_snntorch = spk_rec2[:, 0, nrn].sum()\n",
    "print(f\"Fenrir spike sum: {sum_fenrir}\")\n",
    "print(f\"snntorch spike sum: {sum_snntorch}\")\n",
    "\n",
    "multiplier = 10\n",
    "scale = net.fc2.quant_weight().scale.cpu().detach().numpy()\n",
    "thr = fenrir.get_threshold(net.fc2, net.lif2)*multiplier\n",
    "\n",
    "x_start = 0\n",
    "x_end   = 100\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 7))\n",
    "ax[0].plot(x, nrn_mem[f\"{nrn}\"], color='red', linewidth=2, alpha=0.5, label=\"TB\")\n",
    "ax[0].plot(mem_rec2[:99, 0, nrn]*multiplier/scale, linestyle='--', color='blue', linewidth=2, alpha=0.5, label=\"snntorch\")\n",
    "ax[0].plot(x, np.full_like(x, thr), linestyle='--', color='black', label=\"Thr\")\n",
    "ax[0].plot(x, np.full_like(x, 0), linestyle=':', color='black', alpha=0.5)\n",
    "ax[1].plot(x, spks[nrn], color='red', linewidth=2, alpha=0.5)\n",
    "ax[1].plot(x, spk_rec2[:99, 0, nrn], linestyle='--', color='blue', linewidth=2, alpha=0.5)\n",
    "ax[0].set_title(\"mem_rec\")\n",
    "ax[1].set_title(\"spk_rec\")\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xlim(x_start, x_end)\n",
    "    a.set_xticks(np.arange(x_start, x_end + 1, 10))\n",
    "    a.legend(loc=\"upper right\")\n",
    "\n",
    "fig.suptitle(f\"Layer 2, Neuron {nrn}\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1272745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_to_signed_int(bstr, bits=12):\n",
    "    \"\"\"Convert binary string to signed integer.\"\"\"\n",
    "    val = int(bstr, 2)\n",
    "    if val >= 2**(bits - 1):\n",
    "        val -= 2**bits\n",
    "    return val\n",
    "\n",
    "names = ['t', 'nrn_addr', 'val']\n",
    "df_mem = pd.read_csv('../vivado/fenrir/fenrir.sim/sim_1/behav/xsim/mem_rec3.csv', names=names)\n",
    "\n",
    "nrn_mem = {str(i) : [] for i in range(10)}\n",
    "\n",
    "for t in range(1, 100):\n",
    "    subset = df_mem[df_mem['t'] == t][['nrn_addr', 'val']].head(4)\n",
    "    val_list = subset['val'].tolist()\n",
    "\n",
    "    nrn_mem['2'].append(bin_to_signed_int(val_list[0][0:12], bits=12))\n",
    "    nrn_mem['1'].append(bin_to_signed_int(val_list[0][12:24], bits=12))\n",
    "    nrn_mem['0'].append(bin_to_signed_int(val_list[0][24:36], bits=12))\n",
    "    nrn_mem['5'].append(bin_to_signed_int(val_list[1][0:12], bits=12))\n",
    "    nrn_mem['4'].append(bin_to_signed_int(val_list[1][12:24], bits=12))\n",
    "    nrn_mem['3'].append(bin_to_signed_int(val_list[1][24:36], bits=12))\n",
    "    nrn_mem['8'].append(bin_to_signed_int(val_list[2][0:12], bits=12))\n",
    "    nrn_mem['7'].append(bin_to_signed_int(val_list[2][12:24], bits=12))\n",
    "    nrn_mem['6'].append(bin_to_signed_int(val_list[2][24:36], bits=12))\n",
    "    nrn_mem['9'].append(bin_to_signed_int(val_list[3][24:36], bits=12))\n",
    "\n",
    "names = ['t', 'nrn_addr']\n",
    "df_spk = pd.read_csv('../vivado/fenrir/fenrir.sim/sim_1/behav/xsim/spk_rec3.csv', names=names)\n",
    "df_spk['nrn_addr'] = df_spk['nrn_addr'].apply(lambda b: int(str(b), 2))\n",
    "\n",
    "x = np.arange(99)\n",
    "spks = np.zeros((10, len(x)))\n",
    "for t, nrn_addr in zip(df_spk['t'], df_spk['nrn_addr']):\n",
    "    if nrn_addr < 10 and t < 99:\n",
    "        spks[nrn_addr, t-3] = 1\n",
    "\n",
    "nrn = 0\n",
    "sum_fenrir   = spks[nrn].sum()\n",
    "sum_snntorch = spk_rec3[:, 0, nrn].sum()\n",
    "print(f\"Fenrir spike sum: {sum_fenrir}\")\n",
    "print(f\"snntorch spike sum: {sum_snntorch}\")\n",
    "\n",
    "multiplier = 10\n",
    "scale = net.fc3.quant_weight().scale.cpu().detach().numpy()\n",
    "thr = fenrir.get_threshold(net.fc3, net.lif3)*multiplier\n",
    "\n",
    "x_start = 0\n",
    "x_end   = 100\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 7))\n",
    "ax[0].plot(x, nrn_mem[f\"{nrn}\"], color='red', linewidth=2, alpha=0.5, label=\"TB\")\n",
    "ax[0].plot(mem_rec3[:99, 0, nrn]*multiplier/scale, linestyle='--', color='blue', linewidth=2, alpha=0.5, label=\"snntorch\")\n",
    "ax[0].plot(x, np.full_like(x, thr), linestyle='--', color='black', label=\"Thr\")\n",
    "ax[0].plot(x, np.full_like(x, 0), linestyle=':', color='black', alpha=0.5)\n",
    "ax[1].plot(x, spks[nrn], color='red', linewidth=2, alpha=0.5)\n",
    "ax[1].plot(x, spk_rec3[:99, 0, nrn], linestyle='--', color='blue', linewidth=2, alpha=0.5)\n",
    "ax[0].set_title(\"mem_rec\")\n",
    "ax[1].set_title(\"spk_rec\")\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xlim(x_start, x_end)\n",
    "    a.set_xticks(np.arange(x_start, x_end + 1, 10))\n",
    "    a.legend(loc=\"upper right\")\n",
    "\n",
    "fig.suptitle(f\"Layer 3, Neuron {nrn}\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b877e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
