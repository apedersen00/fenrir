{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7365bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "in_channels = 2\n",
    "out_channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59568f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel definitions\n",
    "k_edge_detector = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [-1,  8, -1],\n",
    "    [-1, -1, -1]\n",
    "])\n",
    "k_blur = np.array([\n",
    "    [1, 2, 1],\n",
    "    [2, 4, 2],\n",
    "    [1, 2, 1]\n",
    "])\n",
    "k_sharpen = np.array([\n",
    "    [0, -1, 0],\n",
    "    [-1, 5, -1],\n",
    "    [0, -1, 0]\n",
    "])\n",
    "k_identity = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 0]\n",
    "])\n",
    "kernels_channel_indexed = {\n",
    "    0: [k_edge_detector, k_blur],\n",
    "    1: [k_sharpen, k_identity]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_weights(\n",
    "    input_channel: int,\n",
    "    kernel_index: int = 0,\n",
    "    kernel_memory: dict = kernels_channel_indexed\n",
    "):\n",
    "    channel_kernels = kernel_memory[input_channel]\n",
    "\n",
    "    weights = [0] * len(channel_kernels)\n",
    "\n",
    "    for idx, kernel in enumerate(channel_kernels):\n",
    "        \n",
    "        weights[idx] = kernel.flatten()[kernel_index]\n",
    "\n",
    "    return weights\n",
    "\n",
    "get_kernel_weights(input_channel=0, kernel_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simple_kernel_file(output_file=\"kernel_weights.mem\"):\n",
    "    \"\"\"Generate BRAM file for your existing kernels - quick and simple!\"\"\"\n",
    "    \n",
    "    print(f\"Generating {output_file} for visual comparison...\")\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"// Simple kernel weights for visual inspection\\n\")\n",
    "        f.write(\"// Input channels: 0, 1\\n\") \n",
    "        f.write(\"// Output channels: 2 each (edge_detector+blur, sharpen+identity)\\n\")\n",
    "        f.write(\"//\\n\")\n",
    "        \n",
    "        # Process each input channel\n",
    "        for in_ch in [0, 1]:\n",
    "            f.write(f\"// Input Channel {in_ch}\\n\")\n",
    "            \n",
    "            # Process all 9 kernel positions (3x3)\n",
    "            for pos in range(9):\n",
    "                address = in_ch * 9 + pos  # Your new addressing scheme\n",
    "                weights = get_kernel_weights(in_ch, pos)\n",
    "                \n",
    "                # Convert to hex (assuming 6-bit signed, 2 output channels)\n",
    "                hex_weights = []\n",
    "                for w in weights:\n",
    "                    if w < 0:\n",
    "                        w_hex = w + 64  # Convert to 6-bit unsigned\n",
    "                    else:\n",
    "                        w_hex = w\n",
    "                    hex_weights.append(w_hex)\n",
    "                \n",
    "                # Pack: output_ch0 in bits [5:0], output_ch1 in bits [11:6] \n",
    "                packed = hex_weights[0] | (hex_weights[1] << 6)\n",
    "                \n",
    "                row, col = divmod(pos, 3)\n",
    "                f.write(f\"@{address:03X} {packed:03X}  // pos({row},{col}) weights: {weights}\\n\")\n",
    "            \n",
    "            f.write(\"\\n\")\n",
    "    \n",
    "    print(f\"Done! Use INIT_FILE=\\\"{output_file}\\\" in your kernel_bram\")\n",
    "    \n",
    "    # Quick verification\n",
    "    print(\"\\nQuick check:\")\n",
    "    print(\"Channel 0, center position (pos 4):\", get_kernel_weights(0, 4))\n",
    "    print(\"Channel 1, center position (pos 4):\", get_kernel_weights(1, 4))\n",
    "\n",
    "generate_simple_kernel_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_torch_weight(kernels_dict):\n",
    "    input_channels = len(kernels_dict)\n",
    "    output_channels = len(kernels_dict[0])\n",
    "    \n",
    "    torch_weights = torch.zeros(output_channels, input_channels, kernel_size, kernel_size)\n",
    "\n",
    "    for input_channel in range(input_channels):\n",
    "        for output_channel in range(output_channels):\n",
    "            kernel = kernels_dict[input_channel][output_channel]\n",
    "            torch_weights[output_channel, input_channel, :, :] = torch.from_numpy(kernel.astype(np.float32))\n",
    "\n",
    "    return torch_weights \n",
    "\n",
    "convert_to_torch_weight(kernels_channel_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c33cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_torch_layer(kernels_dict):\n",
    "    input_channels = len(kernels_dict)\n",
    "    output_channels = len(kernels_dict[0])\n",
    "\n",
    "    conv_layer = nn.Conv2d(\n",
    "        in_channels=input_channels,\n",
    "        out_channels=output_channels,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=1,\n",
    "        bias=False,\n",
    "        padding_mode='zeros'\n",
    "    )\n",
    "\n",
    "    kernel_weights = convert_to_torch_weight(kernels_dict)\n",
    "    conv_layer.weight.data = kernel_weights\n",
    "    return conv_layer\n",
    "\n",
    "conv = create_torch_layer(kernels_channel_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f13ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_one_channel(\n",
    "    in_channel_index: int,\n",
    "    event_coord: tuple[int, int],\n",
    "    image_dimensions: tuple[int, int],\n",
    "    kernel_size: int = kernel_size,\n",
    "    out_channels: int = out_channels,\n",
    "):\n",
    "\n",
    "    x, y = event_coord\n",
    "    img_w, img_h = image_dimensions\n",
    "    out_feature_maps = np.zeros((img_h, img_w, out_channels), dtype=np.float32)\n",
    "\n",
    "    kernel_offset = kernel_size // 2\n",
    "    for dx in range(-kernel_offset, kernel_offset+1):\n",
    "        for dy in range(-kernel_offset, kernel_offset+1):\n",
    "            kernel_position = (dx + kernel_offset) * kernel_size + (dy + kernel_offset)\n",
    "            kernel_weights = np.array(get_kernel_weights(in_channel_index, kernel_position))\n",
    "            #print(f\"dx: {dx}, dy: {dy} => kernel_position: {kernel_position} => kernel vector weights: {kernel_weights}\")\n",
    "\n",
    "            #print(out_feature_maps[y + dy, x + dx, :]+ kernel_weights)\n",
    "            if 0 <= x + dx < img_w and 0 <= y + dy < img_h:\n",
    "                out_feature_maps[y + dy, x + dx, :] += kernel_weights\n",
    "            \n",
    "\n",
    "    return out_feature_maps\n",
    "\n",
    "result = sim_one_channel(\n",
    "    in_channel_index=1,\n",
    "    event_coord=(5, 3),\n",
    "    image_dimensions=(8,8),\n",
    "    kernel_size=kernel_size,\n",
    "    out_channels=out_channels\n",
    ") + sim_one_channel(\n",
    "    in_channel_index=0,\n",
    "    event_coord=(5, 3),\n",
    "    image_dimensions=(8, 8),\n",
    "    kernel_size=kernel_size,\n",
    "    out_channels=out_channels\n",
    ") + sim_one_channel(\n",
    "    in_channel_index=0,\n",
    "    event_coord=(5, 4),\n",
    "    image_dimensions=(8, 8),\n",
    "    kernel_size=kernel_size,\n",
    "    out_channels=out_channels\n",
    ") + sim_one_channel(\n",
    "    in_channel_index=1,\n",
    "    event_coord=(5, 4),\n",
    "    image_dimensions=(8, 8),\n",
    "    kernel_size=kernel_size,\n",
    "    out_channels=out_channels\n",
    ") + sim_one_channel(\n",
    "    in_channel_index=0,\n",
    "    event_coord=(0,0),\n",
    "    image_dimensions=(8, 8),\n",
    "    kernel_size=kernel_size,\n",
    "    out_channels=out_channels\n",
    ")\n",
    "print(result.shape)\n",
    "# Plot each output channel\n",
    "fig, axes = plt.subplots(1, out_channels, figsize=(5 * out_channels, 4))\n",
    "if out_channels == 1:\n",
    "    axes = [axes]\n",
    "for ch in range(out_channels):\n",
    "    ax = axes[ch]\n",
    "    im = ax.imshow(result[:, :, ch], cmap='Wistia')\n",
    "    ax.set_title(f\"Output channel {ch}\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    # Print values on each cell\n",
    "    for i in range(result.shape[0]):\n",
    "        for j in range(result.shape[1]):\n",
    "            val = result[i, j, ch]\n",
    "            ax.text(j, i, f\"{val:.1f}\", ha='center', va='center', color='white' if abs(val) > 1 else 'black', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936cb9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an input image for torch conv layer\n",
    "event_coord = (5, 3)  # Example event coordinate\n",
    "event_coord2 =  (5, 4)  # Another event coordinate for the second channel\n",
    "event_coord3 = (0, 0)  # Another event coordinate for the first channel\n",
    "event_coord4 = (0, 5)\n",
    "N, C_in, H, W = 1, in_channels, 8, 8\n",
    "input_image = torch.zeros((N, C_in, H, W), dtype=torch.float32)\n",
    "input_image[0, 1, event_coord[1], event_coord[0]] = 1.0  # Set the event at the specified coordinate\n",
    "input_image[0, 0, event_coord[1], event_coord[0]] = 1.0  # Set the event for the second channel as well\n",
    "input_image[0, 1, event_coord2[1], event_coord2[0]] += 1.0  # Set the second event for the second channel\n",
    "input_image[0, 0, event_coord2[1], event_coord2[0]] += 1.0  # Set the second event for the first channel as well\n",
    "input_image[0, 0, event_coord3[1], event_coord3[0]] += 1.0\n",
    "\n",
    "#input_image[0, 1, event_coord3[1], event_coord3[0]] += 1.0  # Set the event for the first channel at (0, 0)\n",
    "input_image[0, 1, event_coord4[1], event_coord4[0]] += 1.0  # Set the event for the first channel at (0, 5)\n",
    "\n",
    "result = conv(input_image)\n",
    "# Plot each output channel from the torch conv layer\n",
    "fig, axes = plt.subplots(1, out_channels, figsize=(5 * out_channels, 4))\n",
    "if out_channels == 1:\n",
    "    axes = [axes]\n",
    "for ch in range(out_channels):\n",
    "    ax = axes[ch]\n",
    "    im = ax.imshow(result[0, ch].detach().numpy(), cmap='Wistia')\n",
    "    ax.set_title(f\"Output channel {ch} (Torch Conv)\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    # Print values on each cell\n",
    "    for i in range(result.shape[2]):\n",
    "        for j in range(result.shape[3]):\n",
    "            val = result[0, ch, i, j].item()\n",
    "            ax.text(j, i, f\"{val:.1f}\", ha='center', va='center', color='black' if abs(val) > 1 else 'black', fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_mem_parser.py\n",
    "\n",
    "def twos_complement(val: int, bits: int) -> int:\n",
    "    \"\"\"\n",
    "    Interpret `val` (0 ≤ val < 2**bits) as a signed two’s-complement\n",
    "    number stored in `bits` bits.\n",
    "    \"\"\"\n",
    "    if val & (1 << (bits - 1)):\n",
    "        val -= (1 << bits)\n",
    "    return val\n",
    "\n",
    "def bram_to_feature_map_vector(\n",
    "    bram_data: int,\n",
    "    out_channels: int = 2,\n",
    "    bits_per_neuron: int = 9\n",
    ") -> list[int]:\n",
    "    \"\"\"\n",
    "    Given the packed integer `bram_data` holding\n",
    "      out_channels * bits_per_neuron\n",
    "    bits (LSB = channel 0), extract a Python list of signed ints.\n",
    "    \"\"\"\n",
    "    mask = (1 << bits_per_neuron) - 1\n",
    "    fm = []\n",
    "    for ch in range(out_channels):\n",
    "        # Vivado: result[ch] = bram_data[ch*bits +: bits]\n",
    "        raw = (bram_data >> (ch * bits_per_neuron)) & mask\n",
    "        signed = twos_complement(raw, bits_per_neuron)\n",
    "        fm.append(signed)\n",
    "    return fm\n",
    "\n",
    "def parse_feature_map_file(\n",
    "    filepath: str,\n",
    "    out_channels: int = 2,\n",
    "    bits_per_neuron: int = 9,\n",
    "    radix: str = 'hex'\n",
    ") -> list[list[int]]:\n",
    "    \"\"\"\n",
    "    Reads each line of `filepath`, interprets it as a single BRAM word\n",
    "    (hex by default), and returns a list of feature-map vectors.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    with open(filepath, 'r', encoding='ascii') as f:\n",
    "        for raw in f:\n",
    "            line = raw.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            # parse the line as an integer\n",
    "            if radix.lower() == 'hex':\n",
    "                bram_data = int(line, 16)\n",
    "            elif radix.lower() == 'bin':\n",
    "                bram_data = int(line, 2)\n",
    "            else:\n",
    "                raise ValueError(\"radix must be 'hex' or 'bin'\")\n",
    "            fm = bram_to_feature_map_vector(\n",
    "                bram_data, out_channels, bits_per_neuron\n",
    "            )\n",
    "            results.append(fm)\n",
    "    return results\n",
    "\n",
    "FILE = r'E:\\rtsprojects\\multi_channel_conv\\multi_channel_conv.sim\\sim_1\\behav\\xsim\\test_mem3.mem'\n",
    "\n",
    "slices_per_line = parse_feature_map_file(\n",
    "    FILE,\n",
    "    out_channels=2,\n",
    "    bits_per_neuron=6,\n",
    "    radix='bin'\n",
    ")\n",
    "count = 0\n",
    "for i, sl in enumerate(slices_per_line):\n",
    "    if sl[0] != 0 or sl[1] != 0:\n",
    "        print(f\"Line {i}: {sl[0]} {sl[1]}\")\n",
    "        count += 1\n",
    "print(f\"Total non-zero lines: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b74239",
   "metadata": {},
   "outputs": [],
   "source": [
    "vivado_output = np.zeros((8, 8, 2), dtype=np.int16)\n",
    "counter = 0\n",
    "for w in range (0, 8):\n",
    "    for h in range(0, 8):\n",
    "        vivado_output[h, w, :] = slices_per_line[w * 8 + h]\n",
    "\n",
    "# Plot each output channel from vivado_output\n",
    "fig, axes = plt.subplots(1, out_channels, figsize=(5 * out_channels, 4))\n",
    "if out_channels == 1:\n",
    "    axes = [axes]\n",
    "for ch in range(out_channels):\n",
    "    ax = axes[ch]\n",
    "    im = ax.imshow(vivado_output[:, :, ch], cmap='Wistia')\n",
    "    ax.set_title(f\"Output channel {ch} (Vivado Output)\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    # Print values on each cell\n",
    "    for i in range(vivado_output.shape[0]):\n",
    "        for j in range(vivado_output.shape[1]):\n",
    "            val = vivado_output[i, j, ch]\n",
    "            ax.text(j, i, f\"{val}\", ha='center', va='center', color='black' if abs(val) > 1 else 'black', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d27dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn-conv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
