{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d560e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNN\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "from snntorch.functional import quant\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "# Quantization\n",
    "import brevitas.nn as qnn\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Tonic\n",
    "import tonic\n",
    "from tonic import DiskCachedDataset\n",
    "from tonic import MemoryCachedDataset\n",
    "from tonic.transforms import Compose, ToFrame, Downsample\n",
    "\n",
    "# Other\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import pyfenrir as fenrir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dcb0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetUtils():\n",
    "    @staticmethod\n",
    "    def beta_clamp(mem, beta):\n",
    "        \"\"\"\n",
    "        Soft-clamping of beta to allow gradients.\n",
    "        \"\"\"\n",
    "        beta_abs = torch.abs(beta)\n",
    "        # Positive side: approximate clamp(mem - beta_abs, min=0)\n",
    "        pos_mask = (mem > 0)\n",
    "        pos_val = F.relu(mem - beta_abs)  # ReLU is differentiable everywhere except 0 (and better than clamp)\n",
    "\n",
    "        # Negative side: approximate clamp(mem + beta_abs, max=0)\n",
    "        neg_mask = (mem < 0)\n",
    "        neg_val = -F.relu(-(mem + beta_abs))  # negative ReLU for negative side\n",
    "\n",
    "        mem_new = torch.where(pos_mask, pos_val, mem)\n",
    "        mem_new = torch.where(neg_mask, neg_val, mem_new)\n",
    "\n",
    "        return mem_new\n",
    "\n",
    "    @staticmethod\n",
    "    def mem_clamp(mem, scale, multiplier, bits=12):\n",
    "        max_val = (2**(bits - 1)) - 1\n",
    "        max_val = max_val * scale / multiplier\n",
    "        min_val = -(2**(bits - 1)) - 1\n",
    "        min_val = min_val * scale / multiplier\n",
    "        mem = torch.clamp(mem, min=min_val, max=max_val)\n",
    "        return mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mem_spk(mem, spk, thr_line=False, vline=False, title=False, ylim_max2=1.25):\n",
    "    # Generate two vertically stacked subplots\n",
    "    fig, ax = plt.subplots(2, figsize=(8, 4), sharex=True, \n",
    "                            gridspec_kw={'height_ratios': [1, 0.4]})\n",
    "\n",
    "    # Plot membrane potential (top subplot)\n",
    "    ax[0].plot(mem)\n",
    "    ax[0].set_ylim([0, ylim_max2])\n",
    "    ax[0].set_ylabel(\"Membrane Potential ($U_{mem}$)\")\n",
    "    ax[0].set_yticks([])  # This line removes the y-axis ticks\n",
    "    if title:\n",
    "        ax[0].set_title(title)\n",
    "    if thr_line:\n",
    "        ax[0].axhline(y=thr_line, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
    "    \n",
    "    # Plot output spikes (bottom subplot)\n",
    "    splt.raster(spk, ax[1], s=400, c=\"black\", marker=\"|\")\n",
    "    plt.ylabel(\"Output Spikes\")\n",
    "    plt.yticks([])\n",
    "    if vline:\n",
    "        ax[1].axvline(x=vline, ymin=0, ymax=1, alpha=0.15, c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
    "\n",
    "    plt.xlabel(\"Time step\")\n",
    "    plt.xlim([0, len(mem)]) # Use the length of the membrane potential for x-axis limit\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(\"/mnt/c/home/temp/lif.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['axes.linewidth'] = 3\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Helvetica\"\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "x_heaviside = np.linspace(-10, 10, 1000)\n",
    "y_heaviside = np.where(x_heaviside < 0, 0, 1)\n",
    "\n",
    "x_dirac = np.linspace(-10, 10, 1000)\n",
    "y_dirac = np.zeros_like(x_dirac)\n",
    "zero_index = np.argmin(np.abs(x_dirac))\n",
    "y_dirac[zero_index] = 1\n",
    "\n",
    "ax[0].plot(x_heaviside, y_heaviside, linewidth=4, label='Heaviside')\n",
    "ax[0].set_ylabel('$S$', loc='top', rotation=0, fontsize=45)\n",
    "ax[0].yaxis.set_label_coords(0.1, 0.75)\n",
    "\n",
    "ax[1].plot(x_dirac, y_dirac, linewidth=4, color='tab:orange', label='Dirac')\n",
    "ax[1].arrow(0, 0, 0, 1, head_width=1.0, head_length=0.15, fc='tab:orange', ec='tab:orange', width = 0.1)\n",
    "ax[1].set_ylabel('$\\\\frac{\\\\partial S}{\\\\partial U}$', loc='top', rotation=0, fontsize=45)\n",
    "ax[1].yaxis.set_label_coords(0.14, 0.7)\n",
    "\n",
    "for a in ax:\n",
    "    a.set_yticks([])\n",
    "    a.set_xticks([0])\n",
    "    a.set_xticklabels(['$\\\\theta$'], fontsize=45)\n",
    "    a.set_ylim(-0.1, 1.2)\n",
    "    a.set_xlim(-10, 10)\n",
    "\n",
    "    a.spines['right'].set_color('none')\n",
    "    a.spines['top'].set_color('none')\n",
    "\n",
    "    a.plot(1, -0.1, \">k\", transform=a.get_yaxis_transform(), clip_on=False, markersize=15)\n",
    "    a.plot(-10, 1, \"^k\", transform=a.get_xaxis_transform(), clip_on=False, markersize=15)\n",
    "\n",
    "    a.set_xlabel('$U$', loc='right', fontsize=45)\n",
    "    a.xaxis.set_label_coords(0.97, -0.04)\n",
    "    a.legend(loc='lower right', fontsize=18, framealpha=1.0)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"/mnt/c/home/temp/spike_diff.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12aa42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_integrate_and_fire(mem, cur=0, threshold=1, time_step=1e-3, R=5.1, C=5e-3):\n",
    "  tau_mem = R*C\n",
    "  spk = (mem > threshold)\n",
    "  mem = mem + (time_step/tau_mem)*(-mem + cur*R) - spk*threshold  # every time spk=1, subtract the threhsold\n",
    "  return mem, spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dd426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_in = torch.cat((torch.zeros(10), torch.ones(190)*0.3), 0)\n",
    "mem = torch.zeros(1)\n",
    "mem_rec = []\n",
    "spk_rec = []\n",
    "\n",
    "num_steps = 200\n",
    "\n",
    "# neuron simulation\n",
    "for step in range(num_steps):\n",
    "  mem, spk = leaky_integrate_and_fire(mem, cur_in[step])\n",
    "  mem_rec.append(mem)\n",
    "  spk_rec.append(spk)\n",
    "\n",
    "# convert lists to tensors\n",
    "mem_rec = torch.stack(mem_rec)\n",
    "spk_rec = torch.stack(spk_rec)\n",
    "\n",
    "plot_mem_spk(mem_rec, spk_rec, thr_line=1, title=\"Leaky Integrate-and-Fire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c11515",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 100\n",
    "threshold = 2.0\n",
    "beta = torch.tensor(0.01)\n",
    "\n",
    "lif     = snn.Leaky(beta=1.0, threshold=threshold, learn_threshold=False, reset_mechanism='zero', reset_delay=False)\n",
    "mem     = lif.init_leaky()\n",
    "\n",
    "spk_in = torch.zeros(num_steps)\n",
    "\n",
    "seed        = 0\n",
    "num_spikes  = 20\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "all_indices = torch.randperm(num_steps)\n",
    "spike_indices = all_indices[:num_spikes]\n",
    "spk_in[spike_indices] = 1.0\n",
    "\n",
    "mem_rec = []\n",
    "spk_rec = []\n",
    "\n",
    "for step in range(num_steps):\n",
    "    cur_in = spk_in[step]\n",
    "    spk, mem = lif(cur_in, mem)\n",
    "    mem = NetUtils.beta_clamp(mem, beta)\n",
    "\n",
    "    mem_rec.append(mem)\n",
    "    spk_rec.append(spk)\n",
    "\n",
    "spk_out = torch.stack(spk_rec)\n",
    "mem_out = torch.stack(mem_rec)\n",
    "\n",
    "fig, ax = plt.subplots(3, figsize=(8, 6), sharex=True, gridspec_kw={'height_ratios': [0.4, 1, 0.4]})\n",
    "\n",
    "splt.raster(spk_in, ax[0], s=400, c=\"black\", marker=\"|\")\n",
    "ax[0].set_ylabel(\"Input Spikes\")\n",
    "ax[0].set_yticks([])\n",
    "\n",
    "ax[1].plot(mem_out)\n",
    "ax[1].set_ylim([0, threshold + 0.25])\n",
    "ax[1].set_ylabel(\"Membrane Potential ($U_{mem}$)\")\n",
    "ax[1].set_yticks([])\n",
    "ax[1].axhline(y=threshold, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
    "\n",
    "splt.raster(spk_out, ax[2], s=400, c=\"black\", marker=\"|\")\n",
    "ax[2].set_ylabel(\"Output Spikes\")\n",
    "ax[2].set_yticks([])\n",
    "\n",
    "ax[2].set_xlabel(\"Time step\")\n",
    "ax[2].set_xlim([0, len(mem_out)])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"/mnt/c/home/temp/simple_lif.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87865dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_size = tonic.datasets.DVSGesture.sensor_size\n",
    "frame_length_us = 10e3*50\n",
    "target_size = (128, 128)\n",
    "n_timesteps = 200\n",
    "\n",
    "def pad_time_dimension(frames, fixed_time_steps=100):\n",
    "    \"\"\"\n",
    "    Pad or truncate the time dimension of frames to a fixed number of time steps.\n",
    "    Input: frames [time, channels, height, width] (numpy or tensor)\n",
    "    Output: frames [fixed_time_steps, channels, height, width] (tensor)\n",
    "    \"\"\"\n",
    "    # Convert to tensor if input is numpy array\n",
    "    if isinstance(frames, np.ndarray):\n",
    "        frames = torch.tensor(frames, dtype=torch.float)\n",
    "    current_time_steps = frames.shape[0]\n",
    "    #print(f\"Current time steps: {current_time_steps}, Fixed time steps: {fixed_time_steps}\")\n",
    "    if current_time_steps > fixed_time_steps:\n",
    "        return frames[:fixed_time_steps]\n",
    "    elif current_time_steps < fixed_time_steps:\n",
    "        return torch.nn.functional.pad(frames, (0, 0, 0, 0, 0, 0, 0, fixed_time_steps - current_time_steps))\n",
    "    return frames\n",
    "\n",
    "transform = Compose([\n",
    "    Downsample(sensor_size=sensor_size, target_size=target_size),\n",
    "    ToFrame(sensor_size=(target_size[0], target_size[1], sensor_size[2]), time_window=frame_length_us),\n",
    "    transforms.Lambda(lambda x: pad_time_dimension(x, fixed_time_steps=n_timesteps)),   # Pad/truncate time dimension\n",
    "    # transforms.Lambda(lambda x: torch.clamp(torch.tensor(x), 0, 1).type(torch.float)),  # Clamp spikes accumulted over time to (0,1)\n",
    "    transforms.Lambda(lambda x: x[:, :, :, :]  ),                                       # Select only ON channel\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "trainset = tonic.datasets.DVSGesture(save_to='../data', train=True, transform=transform)\n",
    "testset = tonic.datasets.DVSGesture(save_to='../data', train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf4a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Get labels from the training set\n",
    "train_labels = [sample[1] for sample in trainset]\n",
    "\n",
    "# Get labels from the testing set\n",
    "test_labels = [sample[1] for sample in testset]\n",
    "\n",
    "# Combine the labels from both sets\n",
    "all_labels = train_labels + test_labels\n",
    "\n",
    "# Count the occurrences of each class\n",
    "class_counts = Counter(all_labels)\n",
    "\n",
    "class_names = [\n",
    "    \"hand_clapping\",\n",
    "    \"right_hand_wave\",\n",
    "    \"left_hand_wave\",\n",
    "    \"right_arm_clockwise\",\n",
    "    \"right_arm_counter_clockwise\",\n",
    "    \"left_arm_clockwise\",\n",
    "    \"left_arm_counter_clockwise\",\n",
    "    \"arm_roll\",\n",
    "    \"air_drums\",\n",
    "    \"air_guitar\",\n",
    "    \"other_gestures\",\n",
    "]\n",
    "\n",
    "# Print the total amount of datapoints for each class\n",
    "print(\"Total amount of datapoints for each class:\")\n",
    "for class_label, count in sorted(class_counts.items()):\n",
    "    class_name = class_names[class_label]\n",
    "    print(f\"Class {class_label} ({class_name}): {count} datapoints\")\n",
    "\n",
    "# Also, let's get the total number of datapoints\n",
    "total_datapoints = len(all_labels)\n",
    "print(f\"\\nTotal number of datapoints: {total_datapoints}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc8a2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "samples     = [1, 3, 6, 10]\n",
    "timesteps   = [3, 0, 0, 0]\n",
    "\n",
    "frames = []\n",
    "labels = []\n",
    "\n",
    "for sample, timestep in zip(samples, timesteps):\n",
    "    data, label = trainset[sample]\n",
    "    frame = data[timestep, 0, :, :].numpy()\n",
    "    frames.append(frame)\n",
    "    labels.append(label)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "for i, a in enumerate(ax.flatten()):\n",
    "    a.imshow(frames[i], cmap='jet')\n",
    "    a.set_title(f'{trainset.classes[labels[i]]}')\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"/mnt/c/home/temp/dvsgesture_example.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a9b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "sample = 4\n",
    "t1 = 10\n",
    "t2 = 20\n",
    "t3 = 30\n",
    "\n",
    "data, label = trainset[sample]\n",
    "frame1 = data[t1, 0, :, :].numpy()\n",
    "\n",
    "noise_level = 0.05\n",
    "noisy_frame = frame1.copy()\n",
    "noise_mask = np.random.rand(*frame1.shape) < noise_level\n",
    "noisy_frame[noise_mask & (frame1 == 0)] = 1\n",
    "\n",
    "subsample_factor = 2\n",
    "subsampled_frame = block_reduce(frame1,\n",
    "                                block_size=(subsample_factor, subsample_factor),\n",
    "                                func=np.max)\n",
    "\n",
    "timebin_frame = np.clip(subsampled_frame, 0, 1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "ax[0].imshow(frame1, cmap='gray_r')\n",
    "ax[0].set_title('Original Frame')\n",
    "\n",
    "ax[1].imshow(noisy_frame, cmap='gray_r')\n",
    "ax[1].set_title(f'With Added Noise ({int(noise_level*100)}%)')\n",
    "\n",
    "ax[2].imshow(subsampled_frame, cmap='gray_r')\n",
    "ax[2].set_title(f'Subsampled by {subsample_factor}x (32x32)')\n",
    "\n",
    "ax[3].imshow(timebin_frame, cmap='gray_r')\n",
    "ax[3].set_title(f'Timebinned')\n",
    "\n",
    "for ax in ax:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "frames = [\n",
    "    noisy_frame,\n",
    "    frame1,\n",
    "    subsampled_frame,\n",
    "    timebin_frame\n",
    "]\n",
    "\n",
    "save_names = [\n",
    "    'frame_raw',\n",
    "    'frame_denoised',\n",
    "    'frame_subsampled',\n",
    "    'frame_timebinned'\n",
    "]\n",
    "\n",
    "mpl.rcParams['axes.linewidth'] = 3\n",
    "\n",
    "for f, name in zip(frames, save_names):\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    ax.imshow(f, cmap='gray_r')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"/mnt/c/home/temp/{name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844041ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 4\n",
    "t1 = 10\n",
    "t2 = 20\n",
    "t3 = 30\n",
    "\n",
    "data, label = trainset[sample]\n",
    "frame1 = data[t1, 0, :, :].numpy()\n",
    "frame2 = data[t2, 0, :, :].numpy()\n",
    "frame3 = data[t3, 0, :, :].numpy()\n",
    "\n",
    "# --- Plotting ---\n",
    "fig, ax = plt.subplots(1, 3, figsize=(8, 3))\n",
    "ax[0].imshow(frame1, cmap='gray_r')\n",
    "ax[1].imshow(frame2, cmap='gray_r')\n",
    "ax[2].imshow(frame3, cmap='gray_r')\n",
    "\n",
    "for i, a in enumerate(ax):\n",
    "    a.set_title(f\"Timestep: {10*i}\")\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])\n",
    "\n",
    "fig.suptitle(f'DVS Gesture, Label: {trainset.classes[label]}')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"/mnt/c/home/temp/dvs_wave.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17583220",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    loss_8b = pd.read_csv('../test_data/8b_fixed_loss_lr_data.csv')['loss']\n",
    "    loss_4b = pd.read_csv('../test_data/4b_fixed_loss_lr_data.csv')['loss']\n",
    "    loss_2b = pd.read_csv('../test_data/2b_fixed_loss_lr_data.csv')['loss']\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please make sure the file paths are correct and the CSV files exist.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Define the Rolling Window Boundaries ---\n",
    "window_size = 50\n",
    "\n",
    "# A helper function to avoid repeating code\n",
    "def get_rolling_stats(loss_series, window):\n",
    "    mean = loss_series.rolling(window=window).mean()\n",
    "    min_val = loss_series.rolling(window=window).min()\n",
    "    max_val = loss_series.rolling(window=window).max()\n",
    "    return mean, min_val, max_val\n",
    "\n",
    "loss_8b_mean, loss_8b_min, loss_8b_max = get_rolling_stats(loss_8b, window_size)\n",
    "loss_4b_mean, loss_4b_min, loss_4b_max = get_rolling_stats(loss_4b, window_size)\n",
    "loss_2b_mean, loss_2b_min, loss_2b_max = get_rolling_stats(loss_2b, window_size)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(11, 4), sharey=True)\n",
    "\n",
    "# Data and titles for looping\n",
    "data_to_plot = [\n",
    "    (loss_8b_mean, loss_8b_min, loss_8b_max, '8-bit Quantization (256 kB)'),\n",
    "    (loss_4b_mean, loss_4b_min, loss_4b_max, '4-bit Quantization (128 kB)'),\n",
    "    (loss_2b_mean, loss_2b_min, loss_2b_max, '2-bit Quantization (64 kB)')\n",
    "]\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    mean, min_val, max_val, title = data_to_plot[i]\n",
    "    \n",
    "    ax.fill_between(mean.index, min_val, max_val, color=colors[i], alpha=0.25)\n",
    "    ax.plot(mean, color=colors[i], lw=2)\n",
    "    \n",
    "    ax.set_title(title, fontsize=12)\n",
    "    \n",
    "    ax.xaxis.set_visible(False)\n",
    "\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.set_xlim(left=window_size)\n",
    "\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_ylim(0, 0.06)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"/mnt/c/home/temp/quant_comp.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    loss_8b = pd.read_csv('../test_data/8b_loss_lr_data.csv')['loss']\n",
    "    loss_4b = pd.read_csv('../test_data/4b_loss_lr_data.csv')['loss']\n",
    "    loss_2b = pd.read_csv('../test_data/2b_loss_lr_data.csv')['loss']\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please make sure the file paths are correct and the CSV files exist.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Define the Rolling Window Boundaries ---\n",
    "window_size = 50\n",
    "\n",
    "# A helper function to avoid repeating code\n",
    "def get_rolling_stats(loss_series, window):\n",
    "    mean = loss_series.rolling(window=window).mean()\n",
    "    min_val = loss_series.rolling(window=window).min()\n",
    "    max_val = loss_series.rolling(window=window).max()\n",
    "    return mean, min_val, max_val\n",
    "\n",
    "loss_8b_mean, loss_8b_min, loss_8b_max = get_rolling_stats(loss_8b, window_size)\n",
    "loss_4b_mean, loss_4b_min, loss_4b_max = get_rolling_stats(loss_4b, window_size)\n",
    "loss_2b_mean, loss_2b_min, loss_2b_max = get_rolling_stats(loss_2b, window_size)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(11, 4), sharey=True)\n",
    "\n",
    "# Data and titles for looping\n",
    "data_to_plot = [\n",
    "    (loss_8b_mean, loss_8b_min, loss_8b_max, '8-bit Quantization (128 kB)'),\n",
    "    (loss_4b_mean, loss_4b_min, loss_4b_max, '4-bit Quantization (128 kB)'),\n",
    "    (loss_2b_mean, loss_2b_min, loss_2b_max, '2-bit Quantization (128 kB)')\n",
    "]\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    mean, min_val, max_val, title = data_to_plot[i]\n",
    "    \n",
    "    ax.fill_between(mean.index, min_val, max_val, color=colors[i], alpha=0.25)\n",
    "    ax.plot(mean, color=colors[i], lw=2)\n",
    "    \n",
    "    ax.set_title(title, fontsize=12)\n",
    "    \n",
    "    ax.xaxis.set_visible(False)\n",
    "\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.set_xlim(left=window_size)\n",
    "\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_ylim(0, 0.06)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"/mnt/c/home/temp/quant_comp_same_mem.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30286ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dvs-fpga-_hAg3Ylq-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
