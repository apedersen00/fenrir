{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01df6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from typing import List, Tuple, Optional\n",
    "import re\n",
    "\n",
    "def read_snn_memory_dumps(\n",
    "    dump_directory: str = \".\",\n",
    "    bits_per_neuron: int = 9,\n",
    "    out_channels: int = 4,\n",
    "    img_width: int = 8,\n",
    "    img_height: int = 8,\n",
    "    dump_pattern: str = \"feature_map_mem_*.mem\"\n",
    ") -> Tuple[np.ndarray, List[str]]:\n",
    "    \"\"\"\n",
    "    Read SNN memory dump files and return organized membrane potential data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dump_directory : str\n",
    "        Directory containing the memory dump files\n",
    "    bits_per_neuron : int\n",
    "        Number of bits per neuron (should match BITS_PER_NEURON from testbench)\n",
    "    out_channels : int\n",
    "        Number of output channels (should match OUT_CHANNELS from testbench)\n",
    "    img_width : int\n",
    "        Image width (should match IMG_WIDTH from testbench)\n",
    "    img_height : int\n",
    "        Image height (should match IMG_HEIGHT from testbench)\n",
    "    dump_pattern : str\n",
    "        Filename pattern for memory dumps\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    membrane_potentials : np.ndarray\n",
    "        4D array with shape (num_dumps, img_height, img_width, out_channels)\n",
    "        Contains signed membrane potential values\n",
    "    dump_files : List[str]\n",
    "        List of dump filenames in order\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find all memory dump files\n",
    "    search_pattern = os.path.join(dump_directory, dump_pattern)\n",
    "    dump_files = glob.glob(search_pattern)\n",
    "    \n",
    "    if not dump_files:\n",
    "        raise FileNotFoundError(f\"No memory dump files found matching pattern: {search_pattern}\")\n",
    "    \n",
    "    # Sort files by dump number (extract number from filename)\n",
    "    def extract_dump_number(filename):\n",
    "        match = re.search(r'feature_map_mem_(\\d+)\\.mem', os.path.basename(filename))\n",
    "        return int(match.group(1)) if match else 0\n",
    "    \n",
    "    dump_files.sort(key=extract_dump_number)\n",
    "    \n",
    "    print(f\"Found {len(dump_files)} memory dump files\")\n",
    "    \n",
    "    # Calculate memory organization\n",
    "    total_memory_locations = img_width * img_height\n",
    "    memory_width_bits = out_channels * bits_per_neuron\n",
    "    \n",
    "    print(f\"Memory organization:\")\n",
    "    print(f\"  - Total locations: {total_memory_locations}\")\n",
    "    print(f\"  - Width per location: {memory_width_bits} bits\")\n",
    "    print(f\"  - Bits per neuron: {bits_per_neuron}\")\n",
    "    print(f\"  - Output channels: {out_channels}\")\n",
    "    print(f\"  - Image size: {img_width}x{img_height}\")\n",
    "    \n",
    "    # Initialize result array\n",
    "    membrane_potentials = np.zeros((len(dump_files), img_height, img_width, out_channels), dtype=np.int32)\n",
    "    \n",
    "    # Process each dump file\n",
    "    for dump_idx, dump_file in enumerate(dump_files):\n",
    "        print(f\"\\nProcessing dump {dump_idx}: {os.path.basename(dump_file)}\")\n",
    "        \n",
    "        try:\n",
    "            # Read binary memory dump\n",
    "            with open(dump_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            # Remove whitespace and empty lines\n",
    "            memory_data = []\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('//'):  # Skip comments\n",
    "                    memory_data.append(line)\n",
    "            \n",
    "            if len(memory_data) != total_memory_locations:\n",
    "                print(f\"Warning: Expected {total_memory_locations} memory locations, got {len(memory_data)}\")\n",
    "            \n",
    "            # Process each memory location\n",
    "            for addr, mem_line in enumerate(memory_data):\n",
    "                if addr >= total_memory_locations:\n",
    "                    break\n",
    "                    \n",
    "                # Convert binary string to integer\n",
    "                if len(mem_line) != memory_width_bits:\n",
    "                    print(f\"Warning: Memory location {addr} has {len(mem_line)} bits, expected {memory_width_bits}\")\n",
    "                    continue\n",
    "                \n",
    "                # Calculate 2D coordinates from linear address\n",
    "                # Assuming row-major addressing: addr = y * img_width + x\n",
    "                y = addr // img_width\n",
    "                x = addr % img_width\n",
    "                \n",
    "                if y >= img_height or x >= img_width:\n",
    "                    print(f\"Warning: Address {addr} maps to invalid coordinates ({x}, {y})\")\n",
    "                    continue\n",
    "                \n",
    "                # Extract each neuron's value from the packed memory word\n",
    "                for ch in range(out_channels):\n",
    "                    # Extract bits for this channel\n",
    "                    start_bit = ch * bits_per_neuron\n",
    "                    end_bit = start_bit + bits_per_neuron\n",
    "                    \n",
    "                    if end_bit > len(mem_line):\n",
    "                        print(f\"Warning: Channel {ch} extends beyond memory word at address {addr}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract binary substring for this neuron\n",
    "                    neuron_bits = mem_line[start_bit:end_bit]\n",
    "                    \n",
    "                    # Convert to signed integer\n",
    "                    neuron_value = binary_to_signed_int(neuron_bits, bits_per_neuron)\n",
    "                    \n",
    "                    # Store in result array\n",
    "                    membrane_potentials[dump_idx, y, x, ch] = neuron_value\n",
    "            \n",
    "            print(f\"  Processed {len(memory_data)} memory locations\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {dump_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return membrane_potentials, [os.path.basename(f) for f in dump_files]\n",
    "\n",
    "def binary_to_signed_int(binary_str: str, bit_width: int) -> int:\n",
    "    \"\"\"\n",
    "    Convert binary string to signed integer using two's complement.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    binary_str : str\n",
    "        Binary string (e.g., \"101010\")\n",
    "    bit_width : int\n",
    "        Number of bits for the representation\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    int\n",
    "        Signed integer value\n",
    "    \"\"\"\n",
    "    if len(binary_str) != bit_width:\n",
    "        raise ValueError(f\"Binary string length ({len(binary_str)}) doesn't match bit width ({bit_width})\")\n",
    "    \n",
    "    # Convert to unsigned integer first\n",
    "    unsigned_val = int(binary_str, 2)\n",
    "    \n",
    "    # Check if MSB is set (negative number in two's complement)\n",
    "    if unsigned_val >= (1 << (bit_width - 1)):\n",
    "        # Convert from two's complement\n",
    "        signed_val = unsigned_val - (1 << bit_width)\n",
    "    else:\n",
    "        signed_val = unsigned_val\n",
    "    \n",
    "    return signed_val\n",
    "\n",
    "def analyze_membrane_potentials(membrane_potentials: np.ndarray, dump_files: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Print analysis of the membrane potential data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    membrane_potentials : np.ndarray\n",
    "        4D array from read_snn_memory_dumps\n",
    "    dump_files : List[str]\n",
    "        List of dump filenames\n",
    "    \"\"\"\n",
    "    num_dumps, height, width, channels = membrane_potentials.shape\n",
    "    \n",
    "    print(f\"\\n=== Membrane Potential Analysis ===\")\n",
    "    print(f\"Shape: {membrane_potentials.shape}\")\n",
    "    print(f\"Data type: {membrane_potentials.dtype}\")\n",
    "    print(f\"Number of dumps: {num_dumps}\")\n",
    "    print(f\"Spatial dimensions: {height}x{width}\")\n",
    "    print(f\"Channels: {channels}\")\n",
    "    \n",
    "    print(f\"\\nValue statistics across all dumps:\")\n",
    "    print(f\"  Min: {np.min(membrane_potentials)}\")\n",
    "    print(f\"  Max: {np.max(membrane_potentials)}\")\n",
    "    print(f\"  Mean: {np.mean(membrane_potentials):.2f}\")\n",
    "    print(f\"  Std: {np.std(membrane_potentials):.2f}\")\n",
    "    \n",
    "    print(f\"\\nNon-zero values per dump:\")\n",
    "    for i in range(num_dumps):\n",
    "        non_zero_count = np.count_nonzero(membrane_potentials[i])\n",
    "        total_elements = height * width * channels\n",
    "        percentage = (non_zero_count / total_elements) * 100\n",
    "        print(f\"  Dump {i} ({dump_files[i]}): {non_zero_count}/{total_elements} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1993dd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 memory dump files\n",
      "Memory organization:\n",
      "  - Total locations: 64\n",
      "  - Width per location: 36 bits\n",
      "  - Bits per neuron: 9\n",
      "  - Output channels: 4\n",
      "  - Image size: 8x8\n",
      "\n",
      "Processing dump 0: feature_map_mem_0.mem\n",
      "  Processed 64 memory locations\n",
      "\n",
      "Processing dump 1: feature_map_mem_1.mem\n",
      "  Processed 64 memory locations\n",
      "\n",
      "Processing dump 2: feature_map_mem_2.mem\n",
      "  Processed 64 memory locations\n",
      "\n",
      "Processing dump 3: feature_map_mem_3.mem\n",
      "  Processed 64 memory locations\n",
      "\n",
      "Processing dump 4: feature_map_mem_4.mem\n",
      "  Processed 64 memory locations\n",
      "\n",
      "Processing dump 5: feature_map_mem_5.mem\n",
      "  Processed 64 memory locations\n",
      "\n",
      "Processing dump 6: feature_map_mem_6.mem\n",
      "  Processed 64 memory locations\n",
      "\n",
      "Processing dump 7: feature_map_mem_7.mem\n",
      "  Processed 64 memory locations\n",
      "\n",
      "Processing dump 8: feature_map_mem_8.mem\n",
      "  Processed 64 memory locations\n"
     ]
    }
   ],
   "source": [
    "dump_directory = r\"E:\\rtsprojects\\general_conv\\general_conv.sim\\test_all\\behav\\xsim\"\n",
    "BITS_PER_NEURON = 9\n",
    "OUT_CHANNELS = 4\n",
    "IMG_WIDTH, IMG_HEIGHT = 8, 8\n",
    "membrane_potentials, dump_files = read_snn_memory_dumps(\n",
    "    dump_directory=dump_directory,\n",
    "    bits_per_neuron=BITS_PER_NEURON,\n",
    "    out_channels=OUT_CHANNELS,\n",
    "    img_width=IMG_WIDTH,\n",
    "    img_height=IMG_HEIGHT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d2e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Union, Tuple, Optional\n",
    "\n",
    "def load_kernel_weights_to_conv2d(\n",
    "    weights_file: Union[str, Path],\n",
    "    file_format: str = \"auto\",\n",
    "    normalize_weights: bool = False,\n",
    "    bias: bool = False\n",
    ") -> Tuple[nn.Conv2d, dict]:\n",
    "    \"\"\"\n",
    "    Load kernel weights from SNN generator and create a PyTorch Conv2d layer.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weights_file : str or Path\n",
    "        Path to the weights file (.json, .npy, or .mem)\n",
    "    file_format : str\n",
    "        File format: \"json\", \"numpy\", \"vivado\", or \"auto\" (detect from extension)\n",
    "    normalize_weights : bool\n",
    "        Whether to normalize weights to [-1, 1] range for better training\n",
    "    bias : bool\n",
    "        Whether to include bias terms in the Conv2d layer\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    conv_layer : nn.Conv2d\n",
    "        PyTorch convolution layer with loaded weights\n",
    "    metadata : dict\n",
    "        Metadata about the loaded weights and layer configuration\n",
    "    \"\"\"\n",
    "    \n",
    "    weights_file = Path(weights_file)\n",
    "    \n",
    "    # Auto-detect file format\n",
    "    if file_format == \"auto\":\n",
    "        if weights_file.suffix == \".json\":\n",
    "            file_format = \"json\"\n",
    "        elif weights_file.suffix == \".npy\":\n",
    "            file_format = \"numpy\"\n",
    "        elif weights_file.suffix == \".mem\":\n",
    "            file_format = \"vivado\"\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot auto-detect format for file: {weights_file}\")\n",
    "    \n",
    "    print(f\"Loading weights from {weights_file} (format: {file_format})\")\n",
    "    \n",
    "    # Load weights based on format\n",
    "    if file_format == \"json\":\n",
    "        weights, config = _load_json_weights(weights_file)\n",
    "    elif file_format == \"numpy\":\n",
    "        weights, config = _load_numpy_weights(weights_file)\n",
    "    elif file_format == \"vivado\":\n",
    "        weights, config = _load_vivado_weights(weights_file)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {file_format}\")\n",
    "    \n",
    "    # Extract configuration\n",
    "    in_channels = config['in_channels']\n",
    "    out_channels = config['out_channels']\n",
    "    kernel_size = config['kernel_size']\n",
    "    bits_per_weight = config.get('bits_per_weight', None)\n",
    "    \n",
    "    print(f\"Loaded weights configuration:\")\n",
    "    print(f\"  Input channels: {in_channels}\")\n",
    "    print(f\"  Output channels: {out_channels}\")\n",
    "    print(f\"  Kernel size: {kernel_size}\")\n",
    "    print(f\"  Bits per weight: {bits_per_weight}\")\n",
    "    print(f\"  Weight shape: {weights.shape}\")\n",
    "    print(f\"  Weight range: [{weights.min()}, {weights.max()}]\")\n",
    "    \n",
    "    # Convert weights to PyTorch format: [out_channels, in_channels, height, width]\n",
    "    # Your format is: [in_channels, out_channels, height, width]\n",
    "    torch_weights = torch.from_numpy(weights).float()\n",
    "    torch_weights = torch_weights.permute(1, 0, 2, 3)  # Transpose to PyTorch format\n",
    "    \n",
    "    # Normalize weights if requested\n",
    "    if normalize_weights:\n",
    "        weight_max = torch.abs(torch_weights).max()\n",
    "        if weight_max > 0:\n",
    "            torch_weights = torch_weights / weight_max\n",
    "            print(f\"Normalized weights by factor {weight_max:.3f}\")\n",
    "    \n",
    "    # Create Conv2d layer\n",
    "    conv_layer = nn.Conv2d(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=kernel_size,\n",
    "        stride=1,\n",
    "        padding=kernel_size // 2,  # Same padding\n",
    "        bias=bias\n",
    "    )\n",
    "    \n",
    "    # Load weights into the layer\n",
    "    with torch.no_grad():\n",
    "        conv_layer.weight.copy_(torch_weights)\n",
    "        if bias:\n",
    "            # Initialize bias to zero\n",
    "            conv_layer.bias.zero_()\n",
    "    \n",
    "    # Prepare metadata\n",
    "    metadata = {\n",
    "        'original_config': config,\n",
    "        'pytorch_shape': list(torch_weights.shape),\n",
    "        'original_range': [float(weights.min()), float(weights.max())],\n",
    "        'normalized': normalize_weights,\n",
    "        'has_bias': bias,\n",
    "        'file_format': file_format,\n",
    "        'source_file': str(weights_file)\n",
    "    }\n",
    "    \n",
    "    if normalize_weights:\n",
    "        metadata['normalization_factor'] = float(weight_max)\n",
    "    \n",
    "    print(f\"Created Conv2d layer: {conv_layer}\")\n",
    "    \n",
    "    return conv_layer, metadata\n",
    "\n",
    "def _load_json_weights(weights_file: Path) -> Tuple[np.ndarray, dict]:\n",
    "    \"\"\"Load weights from JSON file generated by the kernel generator.\"\"\"\n",
    "    with open(weights_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    weights = np.array(data['weights'], dtype=np.float32)\n",
    "    config = data['config']\n",
    "    \n",
    "    return weights, config\n",
    "\n",
    "def _load_numpy_weights(weights_file: Path) -> Tuple[np.ndarray, dict]:\n",
    "    \"\"\"Load weights from numpy file.\"\"\"\n",
    "    weights = np.load(weights_file)\n",
    "    \n",
    "    # Try to load accompanying JSON config file\n",
    "    json_file = weights_file.with_suffix('.json')\n",
    "    if json_file.exists():\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            config = data['config']\n",
    "    else:\n",
    "        # Infer configuration from shape\n",
    "        in_channels, out_channels, kernel_size, _ = weights.shape\n",
    "        config = {\n",
    "            'in_channels': in_channels,\n",
    "            'out_channels': out_channels,\n",
    "            'kernel_size': kernel_size,\n",
    "            'bits_per_weight': None\n",
    "        }\n",
    "        print(f\"Warning: No JSON config found, inferred configuration from shape\")\n",
    "    \n",
    "    return weights.astype(np.float32), config\n",
    "\n",
    "def _load_vivado_weights(weights_file: Path) -> Tuple[np.ndarray, dict]:\n",
    "    \"\"\"Load weights from Vivado .mem file.\"\"\"\n",
    "    \n",
    "    # Parse header to extract configuration\n",
    "    config = {}\n",
    "    data_lines = []\n",
    "    \n",
    "    with open(weights_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('// Input channels:'):\n",
    "                config['in_channels'] = int(line.split(':')[1].strip())\n",
    "            elif line.startswith('// Output channels:'):\n",
    "                config['out_channels'] = int(line.split(':')[1].strip())\n",
    "            elif line.startswith('// Kernel size:'):\n",
    "                kernel_info = line.split(':')[1].strip()\n",
    "                kernel_size = int(kernel_info.split('x')[0])\n",
    "                config['kernel_size'] = kernel_size\n",
    "            elif line.startswith('// Bits per weight:'):\n",
    "                config['bits_per_weight'] = int(line.split(':')[1].strip())\n",
    "            elif line.startswith('@') and not line.startswith('//'):\n",
    "                data_lines.append(line)\n",
    "    \n",
    "    # Validate configuration\n",
    "    required_keys = ['in_channels', 'out_channels', 'kernel_size', 'bits_per_weight']\n",
    "    for key in required_keys:\n",
    "        if key not in config:\n",
    "            raise ValueError(f\"Could not extract {key} from Vivado file header\")\n",
    "    \n",
    "    # Parse data lines and reconstruct weights\n",
    "    in_channels = config['in_channels']\n",
    "    out_channels = config['out_channels']\n",
    "    kernel_size = config['kernel_size']\n",
    "    bits_per_weight = config['bits_per_weight']\n",
    "    \n",
    "    weights = np.zeros((in_channels, out_channels, kernel_size, kernel_size), dtype=np.int32)\n",
    "    \n",
    "    for line in data_lines:\n",
    "        # Parse line: @ADDRESS HEXDATA // comment\n",
    "        parts = line.split()\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "            \n",
    "        address = int(parts[0][1:], 16)  # Remove @ and convert hex to int\n",
    "        hex_data = parts[1]\n",
    "        packed_value = int(hex_data, 16)\n",
    "        \n",
    "        # Decode address\n",
    "        total_positions = kernel_size * kernel_size\n",
    "        in_ch = address // total_positions\n",
    "        pos = address % total_positions\n",
    "        row = pos // kernel_size\n",
    "        col = pos % kernel_size\n",
    "        \n",
    "        # Unpack weights for all output channels\n",
    "        for out_ch in range(out_channels):\n",
    "            # Extract bits for this channel\n",
    "            shift = out_ch * bits_per_weight\n",
    "            mask = (1 << bits_per_weight) - 1\n",
    "            weight_unsigned = (packed_value >> shift) & mask\n",
    "            \n",
    "            # Convert to signed\n",
    "            if weight_unsigned >= (1 << (bits_per_weight - 1)):\n",
    "                weight_signed = weight_unsigned - (1 << bits_per_weight)\n",
    "            else:\n",
    "                weight_signed = weight_unsigned\n",
    "                \n",
    "            weights[in_ch, out_ch, row, col] = weight_signed\n",
    "    \n",
    "    return weights.astype(np.float32), config\n",
    "\n",
    "def create_snn_conv_comparison(\n",
    "    weights_file: Union[str, Path],\n",
    "    input_tensor: torch.Tensor,\n",
    "    normalize_weights: bool = True\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Create a comparison between SNN-style convolution and standard Conv2d.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weights_file : str or Path\n",
    "        Path to the weights file\n",
    "    input_tensor : torch.Tensor\n",
    "        Input tensor to test with, shape: [batch, channels, height, width]\n",
    "    normalize_weights : bool\n",
    "        Whether to normalize weights\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Results containing conv layer, output, and metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load weights and create Conv2d layer\n",
    "    conv_layer, metadata = load_kernel_weights_to_conv2d(\n",
    "        weights_file, \n",
    "        normalize_weights=normalize_weights\n",
    "    )\n",
    "    \n",
    "    # Apply convolution\n",
    "    conv_layer.eval()\n",
    "    with torch.no_grad():\n",
    "        output = conv_layer(input_tensor)\n",
    "    \n",
    "    return {\n",
    "        'conv_layer': conv_layer,\n",
    "        'output': output,\n",
    "        'metadata': metadata,\n",
    "        'input_shape': list(input_tensor.shape),\n",
    "        'output_shape': list(output.shape)\n",
    "    }\n",
    "\n",
    "def visualize_kernels(conv_layer: nn.Conv2d, save_path: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Visualize the kernels in a Conv2d layer.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    conv_layer : nn.Conv2d\n",
    "        The convolution layer to visualize\n",
    "    save_path : str, optional\n",
    "        Path to save the visualization\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        weights = conv_layer.weight.detach().cpu().numpy()\n",
    "        out_channels, in_channels, h, w = weights.shape\n",
    "        \n",
    "        # Create subplot grid\n",
    "        fig, axes = plt.subplots(out_channels, in_channels, figsize=(in_channels*2, out_channels*2))\n",
    "        if out_channels == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        if in_channels == 1:\n",
    "            axes = axes.reshape(-1, 1)\n",
    "            \n",
    "        for out_ch in range(out_channels):\n",
    "            for in_ch in range(in_channels):\n",
    "                ax = axes[out_ch, in_ch] if out_channels > 1 else axes[in_ch]\n",
    "                kernel = weights[out_ch, in_ch]\n",
    "                \n",
    "                im = ax.imshow(kernel, cmap='coolwarm', vmin=weights.min(), vmax=weights.max())\n",
    "                ax.set_title(f'Out:{out_ch}, In:{in_ch}')\n",
    "                ax.axis('off')\n",
    "                \n",
    "                # Add colorbar\n",
    "                plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            print(f\"Kernel visualization saved to {save_path}\")\n",
    "        else:\n",
    "            plt.show()\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"Matplotlib not available for visualization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010a9eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from C:\\Users\\alext\\fenrir\\python\\conv_test_scripts\\kernel_weights.json (format: json)\n",
      "Loaded weights configuration:\n",
      "  Input channels: 4\n",
      "  Output channels: 4\n",
      "  Kernel size: 3\n",
      "  Bits per weight: 6\n",
      "  Weight shape: (4, 4, 3, 3)\n",
      "  Weight range: [-2.0, 8.0]\n",
      "Created Conv2d layer: Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    }
   ],
   "source": [
    "weights_file = r'C:\\Users\\alext\\fenrir\\python\\conv_test_scripts\\kernel_weights.json'\n",
    "conv_layer, metadata = load_kernel_weights_to_conv2d(\n",
    "    weights_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9fbbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn-conv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
